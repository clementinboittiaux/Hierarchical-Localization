{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6e5200-7d6e-4e32-a299-9dda571fce7b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import tqdm\n",
    "import torch\n",
    "import pycolmap\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from hloc import extract_features, extractors\n",
    "from hloc.utils.base_model import dynamic_load\n",
    "from pathlib import Path\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "im_dir = Path('/workspace/TourEiffelClean/EiffelTower/global/images/')\n",
    "rec_dir = Path('/workspace/TourEiffelClean/EiffelTower/global/sfm/')\n",
    "conf = extract_features.confs['netvlad']\n",
    "device = 'cuda:0'\n",
    "\n",
    "\n",
    "class ImageDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        image_dir,\n",
    "        reconstruction_dir,\n",
    "        resize_max=1024,\n",
    "        positives_num=20,\n",
    "        negatives_num=100,\n",
    "        positives_distance=3,\n",
    "        negatives_distance=10\n",
    "    ):\n",
    "        print('Loading reconstruction.')\n",
    "        reconstruction = pycolmap.Reconstruction(reconstruction_dir)\n",
    "        \n",
    "        print('Processing positives.')\n",
    "        image_names = []\n",
    "        image_tvecs = []\n",
    "        for image in reconstruction.images.values():\n",
    "            if image.name[:4] != '2015':\n",
    "                image_names.append(image.name)\n",
    "                image_tvecs.append(-image.rotmat().T @ image.tvec)\n",
    "        image_names = np.array(image_names)\n",
    "        image_tvecs = np.stack(image_tvecs)\n",
    "\n",
    "        positives = {}\n",
    "        for image_name, image_tvec in tqdm.tqdm(list(zip(image_names, image_tvecs))):\n",
    "            image_distances = np.linalg.norm(image_tvecs - image_tvec, axis=1)\n",
    "            image_positives_args = image_distances < positives_distance\n",
    "            image_positives = image_names[image_positives_args]\n",
    "            image_distances = image_distances[image_positives_args]\n",
    "            image_positives = image_positives[np.argsort(image_distances)]\n",
    "            image_positives = [pos for pos in image_positives if pos[:4] != image_name[:4]]\n",
    "            if len(image_positives) >= 3:\n",
    "                positives[image_name] = image_positives[:positives_num]\n",
    "\n",
    "        print(f'Kept {len(positives)/len(image_names)*100:.2f}% images with sufficient positives.')\n",
    "        \n",
    "        args_valid = np.isin(image_names, list(positives))\n",
    "        image_names = image_names[args_valid]\n",
    "        image_tvecs = image_tvecs[args_valid]\n",
    "        \n",
    "        self.image_dir = image_dir\n",
    "        self.reconstruction_dir = reconstruction_dir\n",
    "        self.resize_max = resize_max\n",
    "        self.positives_num = positives_num\n",
    "        self.negatives_num = negatives_num\n",
    "        self.positives_distance = positives_distance\n",
    "        self.negatives_distance = negatives_distance\n",
    "        self.image_names = image_names\n",
    "        self.image_tvecs = image_tvecs\n",
    "        self.positives = positives\n",
    "        self.negatives = {}\n",
    "        self.query_only = False\n",
    "    \n",
    "    def load_image(self, image_name):\n",
    "        image = cv2.imread(str(self.image_dir / image_name))\n",
    "        size = np.array(image.shape[1::-1])\n",
    "        new_size = tuple(map(round, size * self.resize_max / size.max()))\n",
    "        image = cv2.resize(image, new_size, interpolation=cv2.INTER_AREA)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = torch.tensor(image).movedim(2, 0) / 255\n",
    "        return image\n",
    "    \n",
    "    def random_negatives(self, idx):\n",
    "        query_tvec = self.image_tvecs[idx]\n",
    "        query_dists = np.linalg.norm(self.image_tvecs - query_tvec, axis=1)\n",
    "        query_negative_names = self.image_names[query_dists >= self.negatives_distance]\n",
    "        np.random.shuffle(query_negative_names)\n",
    "        return query_negative_names[:self.negatives_num].tolist()\n",
    "    \n",
    "    def compute_negatives(self, m, loader, dev):\n",
    "        print('Computing all descriptors.')\n",
    "        descs = torch.full((len(self), 4096), torch.nan, device=dev)\n",
    "        with torch.no_grad():\n",
    "            m.eval()\n",
    "            self.query_only = True\n",
    "            for qidx, qim in tqdm.tqdm(loader):\n",
    "                descs[qidx.item()] = m({'image': qim.to(dev, non_blocking=True)})['global_descriptor'][0]\n",
    "            self.query_only = False\n",
    "            m.train()\n",
    "        \n",
    "        print('Computing negatives.')\n",
    "        for qidx in tqdm.tqdm(range(len(self))):\n",
    "            qdesc = descs[qidx]\n",
    "            if ~qdesc.isnan().any():\n",
    "                qname = self.image_names[qidx]\n",
    "                qtvec = self.image_tvecs[qidx]\n",
    "                qdists = np.linalg.norm(self.image_tvecs - qtvec, axis=1)\n",
    "                qdesc_dists = torch.square(descs - qdesc).sum(dim=1)\n",
    "                qdesc_dists[qdists < self.negatives_distance] = torch.nan\n",
    "                qnegs = qdesc_dists.argsort()\n",
    "                qnegs = qnegs[~qdesc_dists[qnegs].isnan()].cpu().numpy()\n",
    "                self.negatives[qname] = self.image_names[qnegs[:self.negatives_num]].tolist()\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        query_name = self.image_names[idx]\n",
    "        query_image = self.load_image(query_name)\n",
    "        \n",
    "        if self.query_only:\n",
    "            return idx, query_image\n",
    "        \n",
    "        positive_names = self.positives[query_name]\n",
    "        positive_images = [self.load_image(pos) for pos in positive_names]\n",
    "        \n",
    "        negative_names = self.negatives[query_name]\n",
    "        negative_images = [self.load_image(neg) for neg in negative_names]\n",
    "        \n",
    "        return query_image, positive_images, negative_images\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc94541f-0bd7-4c8c-b0df-ab3a64542ae5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Model = dynamic_load(extractors, conf['model']['name'])\n",
    "model = Model(conf['model']).train().requires_grad_(True).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e38f25-c504-4618-8908-f3099a7ad83f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = ImageDataset(\n",
    "    image_dir=im_dir,\n",
    "    reconstruction_dir=rec_dir,\n",
    "    resize_max=512,\n",
    "    positives_num=15,\n",
    "    negatives_num=20\n",
    ")\n",
    "\n",
    "dataset_idxs = np.arange(len(dataset))\n",
    "np.random.shuffle(dataset_idxs)\n",
    "train_idxs = dataset_idxs[100:]\n",
    "test_idxs = dataset_idxs[:100]\n",
    "train_dataset = torch.utils.data.Subset(dataset, train_idxs)\n",
    "test_dataset = torch.utils.data.Subset(dataset, test_idxs)\n",
    "for test_idx in test_idxs:\n",
    "    dataset.negatives[dataset.image_names[test_idx]] = dataset.random_negatives(test_idx)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, num_workers=16, shuffle=True, pin_memory=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, num_workers=16, shuffle=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6497df-487c-4756-ba32-ae464cfa2141",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_tuple_loss(m, tup, marg, dev):\n",
    "    qim, pims, nims = tup\n",
    "    pred_q = m({'image': qim.to(dev, non_blocking=True)})['global_descriptor'][0]\n",
    "    pred_ps = [m({'image': pim.to(dev, non_blocking=True)})['global_descriptor'][0] for pim in pims]\n",
    "    pred_ns = [m({'image': nim.to(dev, non_blocking=True)})['global_descriptor'][0] for nim in nims]\n",
    "\n",
    "    pred_min = torch.square(torch.stack(pred_ps) - pred_q).sum(dim=1).min()\n",
    "    distances_ns = torch.square(torch.stack(pred_ns) - pred_q).sum(dim=1)\n",
    "    tup_loss = torch.clip(pred_min + marg - distances_ns, min=0).sum()\n",
    "    \n",
    "    return tup_loss\n",
    "\n",
    "\n",
    "margin = 0.1\n",
    "batch_size = 4\n",
    "eval_interval = 200\n",
    "\n",
    "it = 0\n",
    "it_loss = 0\n",
    "\n",
    "writer = SummaryWriter('logs/full512/')\n",
    "\n",
    "optimizer.zero_grad()\n",
    "\n",
    "for epoch in range(50):\n",
    "    \n",
    "    dataset.compute_negatives(model, train_loader, device)\n",
    "    \n",
    "    for tupl in tqdm.tqdm(train_loader):\n",
    "        tupl_loss = compute_tuple_loss(model, tupl, margin, device)\n",
    "        \n",
    "        tupl_loss.backward()\n",
    "        \n",
    "        it += 1\n",
    "        it_loss += tupl_loss.item()\n",
    "        \n",
    "        if it % batch_size == 0:\n",
    "            optimizer.step()\n",
    "            \n",
    "            writer.add_scalar('train loss', it_loss, it // batch_size)\n",
    "            writer.flush()\n",
    "            \n",
    "            if (it // batch_size) % eval_interval == 0:\n",
    "                with torch.no_grad():\n",
    "                    model.eval()\n",
    "                    test_loss = 0\n",
    "                    for tupl in test_loader:\n",
    "                        test_loss += compute_tuple_loss(model, tupl, margin, device).item()\n",
    "                    writer.add_scalar('val loss', test_loss, it // batch_size)\n",
    "                    model.train()\n",
    "                    \n",
    "                    torch.save({\n",
    "                        'netvlad': model.state_dict(),\n",
    "                        'optimizer': optimizer.state_dict()\n",
    "                    }, f'checkpoints/full512/iter{it // batch_size:06d}.pt')\n",
    "            \n",
    "            it_loss = 0\n",
    "            optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7a3305-80b8-49a1-bc67-0142e43ed299",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
