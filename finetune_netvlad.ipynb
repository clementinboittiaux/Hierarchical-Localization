{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6e5200-7d6e-4e32-a299-9dda571fce7b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import tqdm\n",
    "import torch\n",
    "import pycolmap\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from hloc import extract_features, extractors\n",
    "from hloc.utils.base_model import dynamic_load\n",
    "from pathlib import Path\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "im_dir = Path('/workspace/TourEiffelClean/EiffelTower/global/images/')\n",
    "rec_dir = Path('/workspace/TourEiffelClean/EiffelTower/global/sfm/')\n",
    "rep_path = Path('representations.pt')\n",
    "conf = extract_features.confs['netvlad']\n",
    "device = 'cuda:1'\n",
    "\n",
    "\n",
    "class ImageDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, reconstruction_dir):\n",
    "        print('Loading reconstruction.')\n",
    "        reconstruction = pycolmap.Reconstruction(reconstruction_dir)\n",
    "        \n",
    "        print('Processing positives and negatives.')\n",
    "        image_names = []\n",
    "        image_tvecs = []\n",
    "        for image in reconstruction.images.values():\n",
    "            if image.name[:4] != '2015':\n",
    "                image_names.append(image.name)\n",
    "                image_tvecs.append(-image.rotmat().T @ image.tvec)\n",
    "        image_names = np.array(image_names)\n",
    "        image_tvecs = np.stack(image_tvecs)\n",
    "\n",
    "        positives = {}\n",
    "        for image_name, image_tvec in tqdm.tqdm(list(zip(image_names, image_tvecs))):\n",
    "            image_distances = np.linalg.norm(image_tvecs - image_tvec, axis=1)\n",
    "            image_positives_args = image_distances < 3\n",
    "            image_positives = image_names[image_positives_args]\n",
    "            image_distances = image_distances[image_positives_args]\n",
    "            image_positives = image_positives[np.argsort(image_distances)]\n",
    "            image_positives = [pos for pos in image_positives if pos[:4] != image_name[:4]]\n",
    "            if len(image_positives) >= 3:\n",
    "                positives[image_name] = image_positives[:15]  # max 15 positives per image\n",
    "\n",
    "        print(f'Kept {len(positives) / len(image_names) * 100:.2f}% images with sufficient positives.')\n",
    "        \n",
    "        self.image_names = image_names\n",
    "        self.image_tvecs = image_tvecs\n",
    "        self.positives = positives\n",
    "        self.valid_names = list(positives)\n",
    "        self.representations = {}\n",
    "        self.negatives = {}\n",
    "        self.train = True\n",
    "    \n",
    "    def load_negatives(self, query_name):\n",
    "        if self.train:\n",
    "            query_tvec = self.image_tvecs[self.image_names == query_name]\n",
    "            query_distances = np.linalg.norm(self.image_tvecs - query_tvec, axis=1)\n",
    "            query_negative_names = self.image_names[query_distances > 10]\n",
    "            np.random.shuffle(query_negative_names)\n",
    "            return query_negative_names[:20].tolist()\n",
    "        else:\n",
    "            return self.negatives[query_name]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        query_name = self.valid_names[idx]\n",
    "        positive_names = self.positives[query_name]\n",
    "        negative_names = self.load_negatives(query_name)\n",
    "        \n",
    "        query_image = self.representations[query_name]\n",
    "        positive_images = [self.representations[pos] for pos in positive_names]\n",
    "        negative_images = [self.representations[neg] for neg in negative_names]\n",
    "        \n",
    "        return query_image, positive_images, negative_images\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.valid_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123f000c-543a-43d0-bbc9-7f9ed80ddb1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Model = dynamic_load(extractors, conf['model']['name'])\n",
    "\n",
    "dataset = ImageDataset(reconstruction_dir=rec_dir)\n",
    "\n",
    "if rep_path.exists():\n",
    "    dataset.representations = torch.load(rep_path)\n",
    "else:\n",
    "    print('Compute image representations.')\n",
    "    representation_model = Model({'name': 'netvlad', 'whiten': False}).eval().requires_grad_(False).to(device)\n",
    "    representation_model.netvlad = torch.nn.Identity()\n",
    "    representations_dataset = extract_features.ImageDataset(im_dir, conf['preprocessing'], dataset.image_names.tolist())\n",
    "    loader = torch.utils.data.DataLoader(\n",
    "        representations_dataset,\n",
    "        num_workers=1, shuffle=False, pin_memory=True\n",
    "    )\n",
    "    for idx, data in enumerate(tqdm.tqdm(loader)):\n",
    "        rname = representations_dataset.names[idx]\n",
    "        dataset.representations[rname] = representation_model({'image': data['image'].to(device, non_blocking=True)})['global_descriptor'][0].cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b660f1bb-330e-476b-b612-30d211dd7da3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_idxs = np.arange(len(dataset))\n",
    "np.random.shuffle(dataset_idxs)\n",
    "train_idxs = dataset_idxs[100:]\n",
    "test_idxs = dataset_idxs[:100]\n",
    "train_dataset = torch.utils.data.Subset(dataset, train_idxs)\n",
    "test_dataset = torch.utils.data.Subset(dataset, test_idxs)\n",
    "for test_idx in test_idxs:\n",
    "    tname = dataset.valid_names[test_idx]\n",
    "    dataset.negatives[tname] = dataset.load_negatives(tname)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, num_workers=12, shuffle=True, pin_memory=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, num_workers=12, shuffle=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc94541f-0bd7-4c8c-b0df-ab3a64542ae5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Model(conf['model']).train().requires_grad_(False).to(device)\n",
    "model.netvlad.centers.requires_grad = True\n",
    "optimizer = torch.optim.Adam([model.netvlad.centers], lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6497df-487c-4756-ba32-ae464cfa2141",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def inference(m, rep):\n",
    "    desc = m.netvlad(rep)\n",
    "    desc = m.whiten(desc)\n",
    "    desc = torch.nn.functional.normalize(desc, dim=1)\n",
    "    return desc\n",
    "\n",
    "\n",
    "def compute_tuple_loss(m, tup, marg, dev):\n",
    "    qim, pims, nims = tup\n",
    "    pred_q = inference(m, qim.to(dev, non_blocking=True))[0]\n",
    "    pred_ps = [inference(m, pim.to(dev, non_blocking=True))[0] for pim in pims]\n",
    "    pred_ns = [inference(m, nim.to(dev, non_blocking=True))[0] for nim in nims]\n",
    "\n",
    "    pred_min = torch.square(torch.stack(pred_ps) - pred_q).sum(dim=1).min()\n",
    "    distances_ns = torch.square(torch.stack(pred_ns) - pred_q).sum(dim=1)\n",
    "    tup_loss = torch.clip(pred_min + marg - distances_ns, min=0).sum()\n",
    "    \n",
    "    return tup_loss\n",
    "\n",
    "\n",
    "margin = 0.1\n",
    "batch_size = 4\n",
    "eval_interval = 200\n",
    "\n",
    "it = 0\n",
    "it_loss = 0\n",
    "\n",
    "writer = SummaryWriter('logs')\n",
    "\n",
    "optimizer.zero_grad()\n",
    "\n",
    "for epoch in range(30):\n",
    "    for tupl in tqdm.tqdm(train_loader):\n",
    "        tupl_loss = compute_tuple_loss(model, tupl, margin, device)\n",
    "        \n",
    "        tupl_loss.backward()\n",
    "        \n",
    "        it += 1\n",
    "        # it_loss += tupl_loss.item()\n",
    "        \n",
    "        if it % batch_size == 0:\n",
    "            optimizer.step()\n",
    "            \n",
    "            if (it // batch_size) % eval_interval == 0:\n",
    "                with torch.no_grad():\n",
    "                    model.eval()\n",
    "                    dataset.train = False\n",
    "                    test_loss = 0\n",
    "                    for tupl in test_loader:\n",
    "                        test_loss += compute_tuple_loss(model, dataset, tupl, margin, device).item()\n",
    "                    writer.add_scalar('test loss', test_loss, it // batch_size)\n",
    "                    writer.flush()\n",
    "                    dataset.train = True\n",
    "                    model.train()\n",
    "                    \n",
    "                    torch.save({\n",
    "                        'centers': model.netvlad.centers.detach().cpu(),\n",
    "                        'optimizer': optimizer.state_dict()\n",
    "                    }, f'checkpoints/iter{it // batch_size: 06d}.pt')\n",
    "            \n",
    "            # it_loss = 0\n",
    "            optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322e1f08-1d9a-406c-96e3-1fce8123f399",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
