{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae6e5200-7d6e-4e32-a299-9dda571fce7b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import tqdm\n",
    "import torch\n",
    "import pycolmap\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from hloc import extract_features, extractors\n",
    "from hloc.utils.base_model import dynamic_load\n",
    "from pathlib import Path\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "conf = extract_features.confs['netvlad']\n",
    "device = 'cuda:1'\n",
    "\n",
    "\n",
    "class ImageDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, image_dir, reconstruction_dir, resize_max=1024):\n",
    "        print('Loading reconstruction.')\n",
    "        reconstruction = pycolmap.Reconstruction(reconstruction_dir)\n",
    "        \n",
    "        print('Processing positives and negatives.')\n",
    "        image_names = []\n",
    "        image_tvecs = []\n",
    "        for image in reconstruction.images.values():\n",
    "            if image.name[:4] != '2015':\n",
    "                image_names.append(image.name)\n",
    "                image_tvecs.append(-image.rotmat().T @ image.tvec)\n",
    "        image_names = np.array(image_names)\n",
    "        image_tvecs = np.stack(image_tvecs)\n",
    "\n",
    "        positives = {}\n",
    "        for image_name, image_tvec in tqdm.tqdm(list(zip(image_names, image_tvecs))):\n",
    "            image_distances = np.linalg.norm(image_tvecs - image_tvec, axis=1)\n",
    "            image_positives_args = image_distances < 3\n",
    "            image_positives = image_names[image_positives_args]\n",
    "            image_distances = image_distances[image_positives_args]\n",
    "            image_positives = image_positives[np.argsort(image_distances)]\n",
    "            image_positives = [pos for pos in image_positives if pos[:4] != image_name[:4]]\n",
    "            if len(image_positives) >= 3:\n",
    "                positives[image_name] = image_positives[:15]  # max 15 positives per image\n",
    "\n",
    "        print(f'Kept {len(positives) / len(image_names) * 100:.2f}% images with sufficient positives.')\n",
    "        \n",
    "        self.image_dir = image_dir\n",
    "        self.resize_max = resize_max\n",
    "        self.image_names = image_names\n",
    "        self.image_tvecs = image_tvecs\n",
    "        self.positives = positives\n",
    "        self.valid_names = list(positives)\n",
    "        self.hard_negatives = {image_name: [] for image_name in positives}\n",
    "        self.train = True\n",
    "    \n",
    "    def load_image(self, image_name):\n",
    "        image = cv2.imread(str(self.image_dir / image_name))\n",
    "        size = np.array(image.shape[1::-1])\n",
    "        new_size = tuple(map(round, size * self.resize_max / size.max()))\n",
    "        image = cv2.resize(image, new_size, interpolation=cv2.INTER_AREA)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = torch.tensor(image).movedim(2, 0) / 255\n",
    "        return image\n",
    "    \n",
    "    def load_negatives(self, query_name):\n",
    "        if self.train:\n",
    "            query_tvec = self.image_tvecs[self.image_names == query_name]\n",
    "            query_distances = np.linalg.norm(self.image_tvecs - query_tvec, axis=1)\n",
    "            query_negatives = self.image_names[query_distances > 10]\n",
    "            hard_negative_names = self.hard_negatives[query_name]\n",
    "            new_negative_names = query_negatives[~np.isin(query_negatives, hard_negative_names)]\n",
    "            np.random.shuffle(new_negative_names)\n",
    "            query_negative_names = hard_negative_names + new_negative_names.tolist()\n",
    "            return query_negative_names[:20]\n",
    "        else:\n",
    "            return self.hard_negatives[query_name]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        query_name = self.valid_names[idx]\n",
    "        positive_names = self.positives[query_name]\n",
    "        negative_names = self.load_negatives(query_name)\n",
    "        \n",
    "        query_image = self.load_image(query_name)\n",
    "        positive_images = [self.load_image(pos) for pos in positive_names]\n",
    "        negative_images = [self.load_image(neg) for neg in negative_names]\n",
    "        \n",
    "        return query_image, positive_images, negative_images, query_name, negative_names\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.valid_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b660f1bb-330e-476b-b612-30d211dd7da3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading reconstruction.\n",
      "Processing positives and negatives.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13168/13168 [00:06<00:00, 2181.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kept 97.62% images with sufficient positives.\n"
     ]
    }
   ],
   "source": [
    "dataset = ImageDataset(\n",
    "    image_dir=Path('/workspace/TourEiffelClean/EiffelTower/global/images/'),\n",
    "    reconstruction_dir=Path('/workspace/TourEiffelClean/EiffelTower/global/sfm/'),\n",
    "    resize_max=1024\n",
    ")\n",
    "\n",
    "dataset_idxs = np.arange(len(dataset))\n",
    "np.random.shuffle(dataset_idxs)\n",
    "train_idxs = dataset_idxs[100:]\n",
    "test_idxs = dataset_idxs[:100]\n",
    "train_dataset = torch.utils.data.Subset(dataset, train_idxs)\n",
    "test_dataset = torch.utils.data.Subset(dataset, test_idxs)\n",
    "for test_idx in test_idxs:\n",
    "    tname = dataset.valid_names[test_idx]\n",
    "    dataset.hard_negatives[tname] = dataset.load_negatives(tname)[:10]\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, num_workers=32, shuffle=True, pin_memory=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, num_workers=32, shuffle=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc94541f-0bd7-4c8c-b0df-ab3a64542ae5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Model = dynamic_load(extractors, conf['model']['name'])\n",
    "model = Model(conf['model']).train().requires_grad_(False).to(device)\n",
    "model.netvlad.centers.requires_grad = True\n",
    "optimizer = torch.optim.Adam([model.netvlad.centers], lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6497df-487c-4756-ba32-ae464cfa2141",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|████████████▍                                                                                                                                                   | 994/12754 [14:40<2:38:24,  1.24it/s]"
     ]
    }
   ],
   "source": [
    "def compute_tuple_loss(m, d, tup, marg, dev):\n",
    "    qim, pims, nims, qname, nnames = tup\n",
    "    pred_q = m({'image': qim.to(dev, non_blocking=True)})['global_descriptor'][0]\n",
    "    pred_ps = [m({'image': pim.to(dev, non_blocking=True)})['global_descriptor'][0] for pim in pims]\n",
    "    pred_ns = [m({'image': nim.to(dev, non_blocking=True)})['global_descriptor'][0] for nim in nims]\n",
    "\n",
    "    pred_min = torch.square(torch.stack(pred_ps) - pred_q).sum(dim=1).min()\n",
    "    distances_ns = torch.square(torch.stack(pred_ns) - pred_q).sum(dim=1)\n",
    "    tup_loss = torch.clip(pred_min + marg - distances_ns, min=0).sum()\n",
    "    \n",
    "    if d.train:\n",
    "        d.hard_negatives[qname[0]] = np.array(nnames).flatten()[distances_ns.detach().argsort().cpu().numpy()[:10]].tolist()\n",
    "    \n",
    "    return tup_loss\n",
    "    \n",
    "\n",
    "margin = 0.1\n",
    "batch_size = 4\n",
    "eval_interval = 200\n",
    "\n",
    "it = 0\n",
    "it_loss = 0\n",
    "\n",
    "writer = SummaryWriter('logs')\n",
    "\n",
    "optimizer.zero_grad()\n",
    "\n",
    "for epoch in range(30):\n",
    "    for tupl in tqdm.tqdm(train_loader):\n",
    "        tupl_loss = compute_tuple_loss(model, dataset, tupl, margin, device)\n",
    "        \n",
    "        tupl_loss.backward()\n",
    "        \n",
    "        it += 1\n",
    "        # it_loss += tupl_loss.item()\n",
    "        \n",
    "        if it % batch_size == 0:\n",
    "            optimizer.step()\n",
    "            \n",
    "            if (it // batch_size) % eval_interval == 0:\n",
    "                with torch.no_grad():\n",
    "                    model.eval()\n",
    "                    dataset.train = False\n",
    "                    test_loss = 0\n",
    "                    for tupl in test_loader:\n",
    "                        test_loss += compute_tuple_loss(model, dataset, tupl, margin, device).item()\n",
    "                    writer.add_scalar('test loss', test_loss, it // batch_size)\n",
    "                    writer.flush()\n",
    "                    dataset.train = True\n",
    "                    model.train()\n",
    "                    \n",
    "                    torch.save({\n",
    "                        'centers': model.netvlad.centers.detach().cpu(),\n",
    "                        'optimizer': optimizer.state_dict()\n",
    "                    }, f'checkpoints/iter{it // batch_size: 06d}.pt')\n",
    "            \n",
    "            # it_loss = 0\n",
    "            optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ec743d-fa6b-4393-882e-2e4045ec3746",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
